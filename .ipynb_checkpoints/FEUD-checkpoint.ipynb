{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48626f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a404f0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import missingno as ms\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daec2a26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datefinder\n",
    "# Example\n",
    "string_with_dates = \"“Family Feud” 11/23/22\"\n",
    "matches = datefinder.find_dates(string_with_dates)\n",
    "next(matches);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f427b",
   "metadata": {},
   "source": [
    "<span>-------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b950e906",
   "metadata": {},
   "source": [
    "<span>-------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33bbacc",
   "metadata": {},
   "source": [
    "# Philo\n",
    "Saved to DVR on Philo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00a41557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page source of full Philo library\n",
    "# !!! Make sure the library is fully expanded before extracting source, or else episodes will not be loaded into HTML code\n",
    "with open('data/philo.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c10072a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some new lines exist already but remove these by joining\n",
    "text = ' '.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "582662ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split on episode title\n",
    "eps = text.split('Family Feud, ')\n",
    "\n",
    "# Get only the first x characters which are the actual episode title\n",
    "# Exclude first element since this is the \"pre-split\"\n",
    "titles = [ep[:28] for ep in eps[1:]]\n",
    "\n",
    "# Split on new element\n",
    "titles = [tit.split(\">\")[0] for tit in titles]\n",
    "\n",
    "# Some titles have new lines in them\n",
    "titles = [tit.replace(\"\\n  \",\"\") for tit in titles]\n",
    "\n",
    "# Some titles are missing a space between \"Episode\" and number\n",
    "titles = [tit.replace(\"Episode\",\"Episode \") for tit in titles]\n",
    "titles = [tit.replace(\"Episode  \",\"Episode \") for tit in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "891b1a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile('[^a-zA-Z0-9, ]')\n",
    "titles = [regex.sub('', tit) for tit in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5872ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile('[^0-9,]')\n",
    "title_nums = [regex.sub('', tit).split(\",\") for tit in titles]\n",
    "\n",
    "df = pd.DataFrame(title_nums, columns=['SeasonNum','EpisodeNum']).drop_duplicates()\n",
    "df = df.astype(int)\n",
    "df = df.sort_values(by=['SeasonNum','EpisodeNum']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9adf53ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "864"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of Philo episodes\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8e7a819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeasonNum</th>\n",
       "      <th>EpisodeNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>17</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>19</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>16</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>21</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>15</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>17</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SeasonNum  EpisodeNum\n",
       "244         17         161\n",
       "631         21          18\n",
       "772         22          45\n",
       "31          15          30\n",
       "530         19         188\n",
       "143         16         113\n",
       "689         21          96\n",
       "53          15          66\n",
       "257         17         174\n",
       "296         18          17"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of Philo episodes\n",
    "df.sort_values(by=['SeasonNum','EpisodeNum'], ascending=False).sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad75fd0",
   "metadata": {},
   "source": [
    "<span>-------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81be991",
   "metadata": {},
   "source": [
    "<span>-------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d1fd69",
   "metadata": {},
   "source": [
    "# TV Guide\n",
    "TV Guide has the best family name data (which is nearly complete) for the early seasons of the show. In some cases, the hometowns are also provided in the description. The date appears to be the date of the last airing on TV (according to Guide), not the original air date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00476dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already downloaded lists of episodes by season from TV Guide\n",
    "# Each season in a sepearte text file\n",
    "# Starts at Season 14 (Steve's first season), no season 12 or 13\n",
    "\n",
    "def tv_guide_data(season_number):\n",
    "    \"\"\" Get df of TV Guide data for one season based on argument \"\"\"\n",
    "    # Read file by season number (14-24)\n",
    "    with open(f'data/tv_guide/S{season_number} TV Guide.txt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Remove new line charcaters which are sporadic throughout\n",
    "    x = ' '.join(lines).replace(\"\\n\",\" \")\n",
    "\n",
    "    # Split on word \"Episode\" and drop unneeded header\n",
    "    x = x.replace(\" Episode \",\"###Episode \").split(\"###\")[2:]\n",
    "\n",
    "    # Remove repeated description text from episode descriptions\n",
    "    # Aim to only keep family names and hometowns\n",
    "    remove_text = [\"\"\"Comedian Steve Harvey hosts as the \"\"\",\n",
    "        \"\"\"Families compete against each by guessing answers to various surveys\"\"\",\n",
    "        \"\"\"Families compete to guess the most popular answers to various survey questions\"\"\",\n",
    "        \"\"\"in this durable game show\"\"\",\n",
    "        \"\"\"Steve Harvey hosts the long-running classic, in which two families compete to guess the answers to various surveys\"\"\",\n",
    "        \"\"\"Steve Harvey hosts the network\\'s new season of the long-running classic, in which two families compete to guess the answers to various surveys\"\"\",\n",
    "        \"\"\"Steve Harvey hosts the the long-running classic, in which two families compete to guess the answers to various surveys\"\"\",\n",
    "        \"\"\"Steve Harvey hosts this hilarious version of the long-running classic, in which two families compete to guess the answers to various surveys\"\"\",\n",
    "        \"\"\"Steve Harvey plays host to two teams, each comprised of five family members, who try to match the answers given to survey questions asked to groups of people\"\"\",\n",
    "        \"\"\"Steve Harvey presents two families who battle it out by answering survey questions for a chance to win cash and prizes\"\"\",\n",
    "        \"\"\"The durable game show in which two teams of five relatives compete for cash and prizes by guessing the most popular answers to questions based on what the \"survey said\" in polls conducted with 100 people\"\"\",\n",
    "        \"\"\"Two families battle against each other by guessing the answers to survey questions\"\"\",\n",
    "        \"\"\"Two families battle each other by trying to match the answers to the survey questions\"\"\",\n",
    "        \"\"\"Two families compete by trying to match the answers to survey questions given to a group of people\"\"\",\n",
    "        \"\"\"Two families compete to guess answers to various surveys\"\"\",\n",
    "        \"\"\"Two families compete to guess the answers to surveys\"\"\",\n",
    "        \"\"\"Two families compete to guess the answers to various surveys\"\"\",\n",
    "        \"\"\"Two families compete to guess the answers to various surveys. Steve Harvey hosts\"\"\",\n",
    "        \"\"\"Two families of five face off to guess the answers with the results of a survey given to a group of people\"\"\",\n",
    "        \"\"\"Two families of five face off to guess the answers with the results of a survey of one hundred people\"\"\",\n",
    "        \"\"\"Two families of five face off to name the top responses to questions posed to 100 people\"\"\",\n",
    "        \"\"\"Two families of five try to guess what the \"survey said\" in polls conducted with 100 people\"\"\",\n",
    "        \"\"\"Two families of five try to guess what the \"survey said\" in polls conducted with 100 people in this durable game show\"\"\",\n",
    "        \"\"\"Two families try to guess what the \"survey said\" in polls conducted with 100 people\"\"\",\n",
    "        \"\"\"Two new families compete for the right to play the returning champions in this classic game show\"\"\",\n",
    "        \"\"\"Two teams of families try to guess the answers to different survey questions\"\"\",\n",
    "        \"\"\"Two teams play against each other to win the grand prize by answering the most popular responses to surveys\"\"\",\n",
    "        \"\"\"Where To Watch\"\"\",\n",
    "        \"\"\".Where To Watch\"\"\"\n",
    "    ]\n",
    "        \n",
    "    # Replace repeated phrases from list with space\n",
    "    for i in range(len(remove_text)):\n",
    "        x = [a.replace(remove_text[i],\" \") for a in x]\n",
    "\n",
    "    # Check if string contains any letters or numbers\n",
    "    def non_empty(words):\n",
    "        return [word for word in words if len(re.compile('[^a-zA-Z0-9]').sub('',word)) > 0]\n",
    "\n",
    "    # Split on double space\n",
    "    split_text = [\"  \"]\n",
    "    for i in range(len(split_text)):\n",
    "        x = [a.split(split_text[i]) for a in x]\n",
    "\n",
    "    # Only keeps values with data\n",
    "    x = [non_empty(a) for a in x]\n",
    "    \n",
    "    def description_stop_words(text):\n",
    "        \"\"\" Remove words that add no info to descriptions (keep only family names and hometowns/state)\"\"\"\n",
    "        if not text: return text\n",
    "        \n",
    "        # Remove non-letters and add leading/traing spaces\n",
    "        text = re.compile('[^a-zA-Z]').sub(' ', text)\n",
    "        text = ' ' + text + ' '\n",
    "        \n",
    "        # Replace stop words with space\n",
    "        # Terrible technique lol\n",
    "        to_replace = ['\"',' to ',' the ',' various ',' family ',' Family ', \" a \", \" against \", \" and \", \" answer \", \" answers \", \" are \", \" based \", \" battle \", \" battles \", \" between \", \" board \", \" by \", \" chance \", \" compete \", \" competes \", \" each \", \" face \", \" families \", \" Fast \", \" five \", \" for \", \" from \", \" game \", \" go \", \" guess \", \" guessing \", \" Harvey \", \" hosted \", \" hosts \", \" in \", \" it \", \" more \", \" off \", \" on \", \" one \", \" other \", \" out \", \" people \", \" play \", \" player \", \" questions \", \" quiz \", \" responses \", \" round \", \" rounds \", \" several \", \" Show \", \" Steve \", \" survey \", \" survey-driven \", \" surveys \", \" teams \", \" the \", \" The \", \" to \", \" top \", \" try \", \" Two \", \" up \", \" various \", \" with \",]\n",
    "        for t in to_replace:\n",
    "            text = text.replace(t,' ')\n",
    "            \n",
    "        return text.strip()\n",
    "    \n",
    "    # Some seasons have zero descriptions so the column may not exist yet in nested list\n",
    "    try:\n",
    "        df = pd.DataFrame(x, columns=['Episode','EpisodeTitle','TVGuideTime','TVGuideDescription'])\n",
    "    except:\n",
    "        df = pd.DataFrame(x, columns=['Episode','EpisodeTitle','TVGuideTime'])\n",
    "        \n",
    "    df = df.fillna(\"\")\n",
    "    \n",
    "    \n",
    "    # Remove stop words if descriptions exist, else create empty column\n",
    "    if \"TVGuideDescription\" in df.columns:\n",
    "        df[\"TVGuideDescription\"] = df[\"TVGuideDescription\"].apply(description_stop_words)\n",
    "    else:\n",
    "        df[\"TVGuideDescription\"] = \"\"\n",
    "        \n",
    "    # Extract season/episode number from text\n",
    "    def get_episode_number(text):\n",
    "        t = text.replace(\"Episode\",\"\")\n",
    "        try:\n",
    "            return int(t)\n",
    "        except:\n",
    "            return t\n",
    "    \n",
    "    # Get family names from game title\n",
    "    def get_family(title, letter):\n",
    "        if letter == 'A': return title.split(' vs ')[0].strip()\n",
    "        if letter == 'B':\n",
    "            try: return title.split(' vs ')[1].split(' Big Money')[0].strip()\n",
    "            except: return \"\"\n",
    "    \n",
    "    # Notes\n",
    "    def get_notes(title):\n",
    "        if \"Big Money Tournament\" in title:\n",
    "            return \"Big Money Tournament\"\n",
    "        else:\n",
    "            return \"\"\n",
    "    \n",
    "    df[\"EpisodeTitle\"] = df.EpisodeTitle.apply(lambda x : re.sub(\"[^a-zA-Z ]\", \"\", x))\n",
    "    df[\"EpisodeTitle\"] = df.EpisodeTitle.str.replace(\" Family\",\"\").replace(\"Episode\",\"\")\n",
    "    \n",
    "    # Create joinable columns\n",
    "    df[\"EpisodeNum\"] = df[\"Episode\"].apply(get_episode_number)\n",
    "    df[\"Season\"] = f\"Season {season_number}\"\n",
    "    df[\"SeasonNum\"] = season_number\n",
    "    \n",
    "    # Get family names from episode title\n",
    "    df[\"FamilyA\"] = df.EpisodeTitle.apply(lambda x : get_family(x, 'A'))\n",
    "    df[\"FamilyB\"] = df.EpisodeTitle.apply(lambda x : get_family(x, 'B'))\n",
    "    \n",
    "    df[\"Notes\"] = df.EpisodeTitle.apply(lambda x : get_notes(x))\n",
    "    df[\"EpisodeTitle\"] = df.EpisodeTitle.str.replace(\"Big Money Tournament Featuring\",\"\").replace(\"the\",\"\")\n",
    "    \n",
    "    # Reorder Columns\n",
    "    df = df[['SeasonNum', 'EpisodeNum', 'Season', 'Episode', 'EpisodeTitle','FamilyA','FamilyB','TVGuideTime', 'TVGuideDescription','Notes']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf6d7870",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run 'tv_guide_data' for all seasons and concat into single dataframe\n",
    "df = pd.DataFrame()\n",
    "for season in range(14,25):\n",
    "    df_ = tv_guide_data(season)\n",
    "    df = pd.concat([df,df_]).reset_index(drop=True)\n",
    "\n",
    "df_guide = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67cad57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeasonNum</th>\n",
       "      <th>EpisodeNum</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>EpisodeTitle</th>\n",
       "      <th>FamilyA</th>\n",
       "      <th>FamilyB</th>\n",
       "      <th>TVGuideTime</th>\n",
       "      <th>TVGuideDescription</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>Season 14</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Pawleck vs Millsap</td>\n",
       "      <td>Pawleck</td>\n",
       "      <td>Millsap</td>\n",
       "      <td>Sat, Jul 13, 2019 30 mins</td>\n",
       "      <td>Pawleck Millsap</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>Season 14</td>\n",
       "      <td>Episode 2</td>\n",
       "      <td>Holcomb vs McKenzie</td>\n",
       "      <td>Holcomb</td>\n",
       "      <td>McKenzie</td>\n",
       "      <td>Sat, May 19, 2018 30 mins</td>\n",
       "      <td>Holcomb vs McKenzie</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>Season 14</td>\n",
       "      <td>Episode 3</td>\n",
       "      <td>McKenzie vs Carlyle</td>\n",
       "      <td>McKenzie</td>\n",
       "      <td>Carlyle</td>\n",
       "      <td>Sat, May 19, 2018 30 mins</td>\n",
       "      <td>McKenzie vs Carlyle</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>Season 14</td>\n",
       "      <td>Episode 4</td>\n",
       "      <td>Thomas vs Hartman</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Hartman</td>\n",
       "      <td>Mon, May 14, 2018 30 mins</td>\n",
       "      <td>Thomas vs Hartman</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>Season 14</td>\n",
       "      <td>Episode 5</td>\n",
       "      <td>Moreland vs Hartman</td>\n",
       "      <td>Moreland</td>\n",
       "      <td>Hartman</td>\n",
       "      <td>Mon, May 14, 2018 30 mins</td>\n",
       "      <td>Moreland vs Hartman</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeasonNum  EpisodeNum     Season    Episode         EpisodeTitle   FamilyA  \\\n",
       "0         14           1  Season 14  Episode 1   Pawleck vs Millsap   Pawleck   \n",
       "1         14           2  Season 14  Episode 2  Holcomb vs McKenzie   Holcomb   \n",
       "2         14           3  Season 14  Episode 3  McKenzie vs Carlyle  McKenzie   \n",
       "3         14           4  Season 14  Episode 4    Thomas vs Hartman    Thomas   \n",
       "4         14           5  Season 14  Episode 5  Moreland vs Hartman  Moreland   \n",
       "\n",
       "    FamilyB                TVGuideTime   TVGuideDescription Notes  \n",
       "0   Millsap  Sat, Jul 13, 2019 30 mins      Pawleck Millsap        \n",
       "1  McKenzie  Sat, May 19, 2018 30 mins  Holcomb vs McKenzie        \n",
       "2   Carlyle  Sat, May 19, 2018 30 mins  McKenzie vs Carlyle        \n",
       "3   Hartman  Mon, May 14, 2018 30 mins    Thomas vs Hartman        \n",
       "4   Hartman  Mon, May 14, 2018 30 mins  Moreland vs Hartman        "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_guide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d7a16f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_guide;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87b8fdb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Episodes: 2013 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SeasonNum\n",
       "14    168\n",
       "15    179\n",
       "16    180\n",
       "17    200\n",
       "18    200\n",
       "19    200\n",
       "20    200\n",
       "21    200\n",
       "22    153\n",
       "23    245\n",
       "24     88\n",
       "Name: EpisodeNum, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Episodes\n",
    "print(\"Total Episodes:\",df_guide.shape[0],'\\n')\n",
    "\n",
    "# Episodes by Season\n",
    "df_guide.groupby('SeasonNum').count()['EpisodeNum']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e823d8e",
   "metadata": {},
   "source": [
    "<span>-------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792f717c",
   "metadata": {},
   "source": [
    "<span>-------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94317991",
   "metadata": {},
   "source": [
    "# trakt.tv (Powered by DirecTV?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d56fb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode_data(season):\n",
    "    \n",
    "    # Get the webpage\n",
    "    url = f\"https://trakt.tv/shows/family-feud-2010/seasons/{season}\"\n",
    "    r = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    # Get the episode titles\n",
    "    episodes = soup.find_all(\"div\", class_=\"row fanarts sortable\")\n",
    "\n",
    "    episode_dict = [] # list of all episode data\n",
    "    episode_data = [] # single episode data\n",
    "\n",
    "    for ep in episodes:\n",
    "        episode_data = []\n",
    "        # Seaon/Episode number e.g. 16x27 \n",
    "        episode_data.append(ep.find(\"span\", class_=\"main-title-sxe\").text)\n",
    "        # Episode title, families\n",
    "        episode_data.append(ep.find(\"span\", class_=\"main-title\").text)\n",
    "        # Date\n",
    "        episode_data.append(ep.find(\"span\", class_=\"convert-date\").text)\n",
    "        # Add episode to list\n",
    "        episode_dict.append(episode_data)\n",
    "\n",
    "    df = pd.DataFrame(episode_dict, columns = ['num','EpisodeTitle','AirDate'])\n",
    "    \n",
    "    # Seems like accurate air dates\n",
    "    df.AirDate = pd.to_datetime(df.AirDate).dt.date\n",
    "    \n",
    "    # Reformat/create columns \n",
    "    def get_family(title, letter):\n",
    "        \n",
    "        if letter == 'A': return re.split(' v | vs ', title)[0].strip()\n",
    "        if letter == 'B':\n",
    "            try: return re.split(' v | vs ', title)[1].split(' Big Money')[0].strip()\n",
    "            except: return \"\"\n",
    "    \n",
    "    def get_notes(title):\n",
    "        if \"Big Money Tournament\" in title:\n",
    "            return \"Big Money Tournament\"\n",
    "        else:\n",
    "            return \"\"\n",
    "        \n",
    "    df[\"SeasonNum\"] = df.num.apply(lambda x : int(x.split('x')[0]))\n",
    "    df[\"EpisodeNum\"] = df.num.apply(lambda x : int(x.split('x')[1]))\n",
    "    \n",
    "    df[\"EpisodeTitle\"] = df.EpisodeTitle.apply(lambda x : re.sub(\"[^a-zA-Z'‘’\\- ]\", \"\", x))\n",
    "    df[\"EpisodeTitle\"] = df.EpisodeTitle.str.replace(\" Family\",\"\")\n",
    "    df[\"EpisodeTitle\"] = df.EpisodeTitle.str.replace(\"Episode\",\"\")\n",
    "    df[\"EpisodeTitle\"] = df.EpisodeTitle.str.replace(\"Summer vs Grace\",\"Summers vs Grace\")\n",
    "    \n",
    "    df[\"FamilyA\"] = df.EpisodeTitle.apply(lambda x : get_family(x, 'A'))\n",
    "    df[\"FamilyB\"] = df.EpisodeTitle.apply(lambda x : get_family(x, 'B'))\n",
    "    \n",
    "    df[\"Notes\"] = df.EpisodeTitle.apply(lambda x : get_notes(x))\n",
    "    \n",
    "    df = df[['SeasonNum', 'EpisodeNum', 'EpisodeTitle', 'AirDate','FamilyA','FamilyB','Notes','num']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d2029b6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for season in range(14,25):\n",
    "    df_ = get_episode_data(season)\n",
    "    df = pd.concat([df,df_])\n",
    "    \n",
    "df_trakt = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "27933c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = ((\"Monts\",\"Montas\"),\n",
    "    (\"Hamshudin\",\"Shamshudin\"),\n",
    "    (\"Alamand\",\"Almand\"),\n",
    "    (\"Midthum\",\"Midthun\"),\n",
    "    (\"Dehart\",\"DeHart\"),\n",
    "    (\"KcKeon\",\"McKeon\"),\n",
    "    (\"De La Rose\",\"De La Rosa\"),\n",
    "    (\"St Fleur\",\"St. Fleur\"),\n",
    "    (\"Loeher\",\"Loehler\"),\n",
    "    (\"Callagher\",\"Gallagher\"),\n",
    "    (\"Lahtam\",\"Latham\"),\n",
    "    (\"Rettmann\",\"Rettman\"),\n",
    "    (\"Chulner\",\"Schulner\"),\n",
    "    (\"Venkataram\",\"Venkatram\"),\n",
    "    (\"Marriett\",\"Merriett\"),\n",
    "    (\"Shellnutt\",\"Shelnutt\"),\n",
    "    (\"Hlases\",\"Hlas\"),\n",
    "    (\"Newbert\",\"Neubert\"),\n",
    "    (\"Leclair\",\"LeClair\"),\n",
    "    (\"Pagn\",\"Pagan\"),\n",
    "    (\"Bellefant\",\"Bellenfant\"),\n",
    "    (\"Benson Jaja\",\"Benson-Jaja\"),\n",
    "    (\"McCary\",\"McCrary\"),\n",
    "    (\"Buchholz\",\"Buccholz\"),\n",
    "    (\"Suddth\",\"Sudduth\"),\n",
    "    (\"Pagn\",\"Pagan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "accf8dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in replacements:\n",
    "    df_trakt = df_trakt.replace(r[0],r[1],regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fcbfae65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_trakt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4e53312c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeasonNum\n",
       "14    180\n",
       "15    180\n",
       "16    180\n",
       "17    200\n",
       "18    200\n",
       "19    200\n",
       "20    200\n",
       "21    181\n",
       "22    166\n",
       "23     89\n",
       "24     18\n",
       "Name: EpisodeNum, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trakt.groupby('SeasonNum').count()['EpisodeNum']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a6697",
   "metadata": {},
   "source": [
    "<span>-------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f9a393",
   "metadata": {},
   "source": [
    "<span>-------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b55d8f",
   "metadata": {},
   "source": [
    "# bobbymgsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61769b96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n"
     ]
    }
   ],
   "source": [
    "pages_str = \"\"\n",
    "for page in range(1,127):\n",
    "    print(page)\n",
    "    url = f'https://bobbymgsk.wordpress.com/category/family-feud/page/{page}/'\n",
    "    page = requests.get(url)\n",
    "    pages_str += page.text\n",
    "    time.sleep(5*random.random())\n",
    "    \n",
    "soup = BeautifulSoup(pages_str, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dad9acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in massive 126 page html file, we love you Bobby McBride <3\n",
    "# # File is the fully (?) expanded version of the \"Family Feud\" category from blog\n",
    "# with open(f\"bobbymgsk.txt\", encoding=\"UTF-8\") as f:\n",
    "#     r = f.read()\n",
    "\n",
    "# # Replace space symbol that decoder missed\n",
    "# r = r.replace('\\xa0', ' ')\n",
    "# r = r.replace('\\n', ' ')\n",
    "\n",
    "# # SLOW # RUNS VERY SLOW #\n",
    "# # Parse to soup and collect list of posts\n",
    "# soup = BeautifulSoup(r, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524eb97e",
   "metadata": {},
   "source": [
    "### Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "51704fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of posts (most posts contain two episodes)\n",
    "# Number of posts is 1260 as of 12/29/2022\n",
    "posts = soup.find_all(\"div\", {\"class\": \"post\"})\n",
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "91270978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Games can start with random titles ...yay... \n",
    "# the following list of titles each designate a new game\n",
    "with open(\"game_titles.txt\", \"r\", encoding=\"UTF-8\") as f:\n",
    "    game_titles = [x.strip().replace('\"', '') for x in f.readlines()]\n",
    "    \n",
    "game_titles[0:10];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "62a61442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_title(post):\n",
    "    try: return post.find('a', href=True).text\n",
    "    except: return \"No Title Found\"\n",
    "\n",
    "def get_family_info(title, num):\n",
    "    title = title.split(':')[1]\n",
    "    try:\n",
    "        family = re.split(' v. | v | vs. | vs ', title)[num]\n",
    "    except:\n",
    "        family=\"\"\n",
    "    for g in game_titles:\n",
    "        family = family.replace(g,'').replace(':','').strip()\n",
    "    family = family.replace('(','$$@(').split('$$@')\n",
    "    name = family[0]\n",
    "    info = family[1:]\n",
    "    return name, info\n",
    "\n",
    "def get_post_version(title):\n",
    "    if \"Celebrity\" in title:\n",
    "        return \"Celebrity\"\n",
    "    else:\n",
    "        return \"Standard\"\n",
    "\n",
    "def has_multiple_backslashes(string):\n",
    "    backslash_count = 0\n",
    "    for char in string:\n",
    "        if char == '\\\\':\n",
    "            backslash_count += 1\n",
    "    if backslash_count > 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_post_date(post, post_title):\n",
    "    spans = post.find_all('span')\n",
    "    if has_multiple_backslashes(post_title):\n",
    "        span_list = [post_title] + [span.text for span in spans]\n",
    "    else:\n",
    "        span_list = [span.text for span in spans] + [post_title]\n",
    "    for span in span_list:\n",
    "        try:\n",
    "            dates = datefinder.find_dates(span)\n",
    "            return next(dates)\n",
    "        except:\n",
    "            pass\n",
    "    return \"\"\n",
    "\n",
    "def get_games_from_post(post):\n",
    "    games = []\n",
    "    for p_tag in post.find_all('p'):\n",
    "        if bool([ele for ele in game_titles if(ele in p_tag.text)]):\n",
    "            game_title = p_tag.text\n",
    "            game_split = game_title.split(':')[0].replace('(','$$@(').split('$$@')\n",
    "            game_header = game_split[0]\n",
    "            game_info = game_split[1:]\n",
    "            games.append([game_title, game_header, game_info])\n",
    "    return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d6136978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Family Feud” 11/5/10\n",
      "“Family Feud” 11/4/10\n",
      "“Family Feud” 11/3/10\n",
      "“Family Feud” 11/2/10\n",
      "“Family Feud” 2/11/13- FIRST-RUN REMATCH\n",
      "“Family Feud” 10/19/10\n",
      "“Family Feud” 10/16/12\n"
     ]
    }
   ],
   "source": [
    "for post in posts: \n",
    "    # Keep track of the number of fast money's per post\n",
    "    # Since every game has a fast money (and they are all denoted with \"FM:\"), we can use this to\n",
    "    # track which games are missing crucial information, like a title or family list\n",
    "    fastmoney_count = 0\n",
    "    \n",
    "    # keep track of each game\n",
    "    games = []\n",
    "    \n",
    "    games.append(get_post_title(post))\n",
    "\n",
    "    p_tags = post.find_all('p')\n",
    "    for p_tag in p_tags:\n",
    "        if 'FM:' in p_tag.text:\n",
    "            fastmoney_count += 1\n",
    "        if bool([ele for ele in game_titles if(ele in p_tag.text)]):\n",
    "            games.append(p_tag.text)\n",
    "            \n",
    "    if len(games) < fastmoney_count+1:\n",
    "        for d in games: print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cbf6129e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "game_count = 0\n",
    "all_games = []\n",
    "for post in posts:\n",
    "    post_title = post.find('a', href=True).text\n",
    "    post_version = get_post_version(post_title)\n",
    "    post_date = get_post_date(post, post_title)\n",
    "    \n",
    "    games = get_games_from_post(post)\n",
    "    for game in games:\n",
    "        [game_title, game_header, game_info] = game\n",
    "        [nameFamilyA, infoFamilyA] = get_family_info(game_title,0)\n",
    "        [nameFamilyB, infoFamilyB] = get_family_info(game_title,1)\n",
    "        \n",
    "        _game = [post_title, post_version, post_date, \n",
    "                 game_title, game_header, game_info, \n",
    "                 nameFamilyA, nameFamilyB, infoFamilyA, infoFamilyB]\n",
    "        \n",
    "        all_games.append(_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a71079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.DataFrame(all_games, columns=['PostTitle', 'Version', 'PostDate', \n",
    "                                         'GameTitle', 'GameHeader', 'GameInfo', \n",
    "                                         'FamilyA', 'FamilyB', 'FamilyAInfo', 'FamilyBInfo'])\n",
    "\n",
    "\n",
    "games['PostDate'] = pd.to_datetime(games['PostDate'], infer_datetime_format=True, errors='coerce').dt.date\n",
    "games = games.fillna(\"\")\n",
    "games = games.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)  \n",
    "games = games.fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfafbb8",
   "metadata": {},
   "source": [
    "### Replace typos from Bobby\n",
    "Determined by comparison from Trakt titles, mostly confirmed via video clips. Why does he do plural last names? Agh!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4a4d5cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = (('Crovetttos','Crovettos'),\n",
    "    ('Collingsworth','Hollingsworth'),\n",
    "    ('Aladenoyers','Aladenoyes'),\n",
    "    ('McLards','McClards'),\n",
    "    ('Olszweski','Olszewski'),\n",
    "    ('McLards','McClards'),\n",
    "    ('Hlaseses','Hlases'),\n",
    "    ('Cartotenutos','Carotenutos'),\n",
    "    ('Boulhac','Roulhac'),\n",
    "    ('Coanses','Coans'),\n",
    "    ('Chesnut','Chestnut'),\n",
    "    ('Keningsbergs','Kenigsberg'),\n",
    "    ('Mokiaoses','Mokiaos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "52f15199",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in replacements:\n",
    "    games = games.replace(r[0],r[1],regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ad21d",
   "metadata": {},
   "source": [
    "### De-pluralize family names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "27f16035",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_trakt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28132/472241159.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrakt_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_trakt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFamilyA\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_trakt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFamilyB\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrakt_names_ending_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrakt_names\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'e'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_non_plural_family\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_trakt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_trakt' is not defined"
     ]
    }
   ],
   "source": [
    "trakt_names = [t.strip() for t in list(df_trakt.FamilyA) + list(df_trakt.FamilyB) if len(t.strip())>0]\n",
    "trakt_names_ending_e = list(set([t for t in trakt_names if t[-1] == 'e']))\n",
    "\n",
    "\n",
    "def get_non_plural_family(name, df_trakt):\n",
    "    try:\n",
    "        name = name.strip()\n",
    "        if name in ['Wis']:\n",
    "            return name\n",
    "        if (name[-2:] == 'es') and (name[:-1] in trakt_names_ending_e):\n",
    "            return name[:-1] \n",
    "        if name[-2:] == 'es':\n",
    "            return name[:-2]\n",
    "        elif name[-1] == 's':\n",
    "            return name[:-1]\n",
    "        else:\n",
    "            return name\n",
    "    except:\n",
    "        return name\n",
    "\n",
    "games['FamilyA_'] = games['FamilyA'].apply(get_non_plural_family)\n",
    "games['FamilyB_'] = games['FamilyB'].apply(get_non_plural_family)\n",
    "\n",
    "games = games.replace(\"’\", \"'\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d7cf33",
   "metadata": {},
   "source": [
    "### Save game list to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45197ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "games.to_csv('games.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd6fa6f",
   "metadata": {},
   "source": [
    "### Testing: Count of Game Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c42d6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "game_titles_df = pd.DataFrame([g.split(\":\")[0] for g in list(games.GameHeader)]).value_counts()\n",
    "game_titles_df;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629d0917",
   "metadata": {},
   "source": [
    "<span>-------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c896d4",
   "metadata": {},
   "source": [
    "<span>-------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d3a09",
   "metadata": {},
   "source": [
    "# All"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8071f2",
   "metadata": {},
   "source": [
    "### Create empty dataframe for all episodes (season, episode dyad) based on IMDB counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4cc9375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From IMDB\n",
    "episode_count = {\n",
    "    14: 180,\n",
    "    15: 180,\n",
    "    16: 180,\n",
    "    17: 200,\n",
    "    18: 200,\n",
    "    19: 200,\n",
    "    20: 200,\n",
    "    21: 175,\n",
    "    22: 166,\n",
    "    23: 180,\n",
    "    24: 81\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "abda26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of season/episode dyads\n",
    "all_eps = []\n",
    "for season in range(14,25):\n",
    "    for episode in range(1,episode_count[season]+1):\n",
    "        all_eps.append([season, episode])\n",
    "df_all = pd.DataFrame(all_eps, columns=['SeasonNum','EpisodeNum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79674490",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Episodes:\", len(df_all),'\\n')\n",
    "df_all.groupby('SeasonNum').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61244b98",
   "metadata": {},
   "source": [
    "### Join Trakt (best family name data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33822be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.merge(df_all, df_trakt, \n",
    "              left_on = ['SeasonNum', 'EpisodeNum'], \n",
    "              right_on = ['SeasonNum', 'EpisodeNum'],\n",
    "              how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbeb53c",
   "metadata": {},
   "source": [
    "### Join IMDB Season 23 Air Dates (Trakt has poor season 23/24 coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce59a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.merge(df_all, df_imdb23, \n",
    "              left_on = ['SeasonNum', 'EpisodeNum'], \n",
    "              right_on = ['SeasonNum', 'EpisodeNum'],\n",
    "              how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a54b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['AirDate'] = df_all['AirDate'].combine_first(df_all['AirDate1'])\n",
    "df_all['AirDate'] = pd.to_datetime(df_all['AirDate']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20023ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all.sort_values(by=['SeasonNum','EpisodeNum'], ascending=False)[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4b64a5",
   "metadata": {},
   "source": [
    "<span>-------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a024ea3",
   "metadata": {},
   "source": [
    "<span>-------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a4855",
   "metadata": {},
   "source": [
    "# Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4df7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_trakt, games[['FamilyB_', 'FamilyA_']], \n",
    "              left_on=['FamilyA', 'FamilyB'], \n",
    "              right_on=['FamilyA_', 'FamilyB_'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4480bc7",
   "metadata": {},
   "source": [
    "### Search by family name in bobbymgsk (both plural and de-pluralized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ce6318",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "name = 'Summers'\n",
    "name_search = games[(games['FamilyA'] == name) | \n",
    "      (games['FamilyB'] == name) | \n",
    "      (games['FamilyA_'] == name) | \n",
    "      (games['FamilyB_'] == name)]\n",
    "\n",
    "name_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8043dc",
   "metadata": {},
   "source": [
    "### Search by family name in Trakt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Montas'\n",
    "name_search = df_trakt[(df_trakt['FamilyA'] == name) | (df_trakt['FamilyB'] == name)]\n",
    "\n",
    "name_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d252a",
   "metadata": {},
   "source": [
    "### Join Trakt and bobbymgsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a17938",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.merge(games[['FamilyB_', 'FamilyA_']], \n",
    "              df_trakt[['FamilyB', 'FamilyA','EpisodeNum','SeasonNum']], \n",
    "              left_on = ['FamilyA_', 'FamilyB_'], \n",
    "              right_on = ['FamilyA', 'FamilyB'],\n",
    "              how='left')\n",
    "\n",
    "df[['SeasonNum','EpisodeNum']] = df[['SeasonNum','EpisodeNum']].fillna(0).astype(int)\n",
    "df = df[df.SeasonNum != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d63ed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['SeasonNum','EpisodeNum'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e25b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"imdb_season_23_airdates.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "lines = [line.replace(',\\n','').split(',')[0:3] for line in lines]\n",
    "df_imdb23 = pd.DataFrame(lines, columns=['SeasonNum','EpisodeNum','AirDate1'])\n",
    "df_imdb23[['SeasonNum','EpisodeNum']] = df_imdb23[['SeasonNum','EpisodeNum']].astype(int)\n",
    "df_imdb23['AirDate1'] = pd.to_datetime(df_imdb23['AirDate1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
